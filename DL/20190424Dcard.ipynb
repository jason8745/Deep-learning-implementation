{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "import pandas as pd\n",
    "#punctuation remove setting\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "#建立類別\n",
    "class WordVector():\n",
    "    def __init__(self, filename, window=2, dim=10):\n",
    "        self.filename = filename\n",
    "        self.window = window\n",
    "        self.dim = dim\n",
    "\n",
    "    def q21_cooccur_matrix(self):\n",
    "        '''\n",
    "        Arguments\n",
    "            filename (str): the filename of an English article\n",
    "            window (int): context window, define the range of the context\n",
    "        Returns\n",
    "            vocab (dict): map keyword into id\n",
    "            inv_vocab (dict): map id back to keyword\n",
    "            cooccur_matrix (np.ndarray): NxN co-occurrence matrix\n",
    "        '''\n",
    "      \n",
    "        df = pd.read_table(self.filename,header =None)\n",
    "        #全部變為小寫\n",
    "        li_n=list()\n",
    "        for line in df[0]:\n",
    "        \n",
    "            li_n.append(line.lower())\n",
    "        allword = list()\n",
    "        for article in li_n:\n",
    "            punct_token = wordpunct_tokenize(article)\n",
    "            #remove string.punctuation\n",
    "            punct_token = [word for word in punct_token if word not in string.punctuation]\n",
    "            allword.append(punct_token)\n",
    "        #建一個list來放\n",
    "        count = list()\n",
    "        for words in allword:\n",
    "            for i in range(len(words)-1):\n",
    "                for j in range(i-self.window,i+1+self.window):\n",
    "                    if (j<0 or j==i) :\n",
    "                        continue\n",
    "                    elif j >len(words)-1:\n",
    "                        break\n",
    "                    else:\n",
    "                        count.append(([words[i],words[j]]))\n",
    "        vocab = {}\n",
    "        i=0\n",
    "        for words in count:\n",
    "            for word in words:\n",
    "                if word not in vocab: \n",
    "                    vocab[word] = i\n",
    "                    i+=1\n",
    "        \n",
    "        inv_vocab = {v: k for k, v in vocab.items()}\n",
    "        #建立一個全0的array\n",
    "        cooccur_matrix = np.zeros([len(vocab),len(vocab)])\n",
    "        \n",
    "        for sets in count:\n",
    "            cooccur_matrix[vocab[sets[0]],vocab[sets[1]]]+=1\n",
    "            cooccur_matrix[vocab[sets[1]],vocab[sets[0]]]+=1\n",
    "        \n",
    "    \n",
    "    \n",
    "        return vocab, inv_vocab, cooccur_matrix\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def q22_word_vectors(self):\n",
    "        '''\n",
    "        Arguments\n",
    "            cooccur_matrix (np.ndarray): NxN co-occurrence matrix\n",
    "            dim (int): dimension of PCA\n",
    "        Returns\n",
    "            word_vector (np.ndarray): Nxdim word-vector matrix\n",
    "        '''\n",
    "        cooccur_matrix =self.q21_cooccur_matrix()[2]\n",
    "        \n",
    "        # Use PCA to reduce dimension\n",
    "        pca=PCA(n_components=self.dim)\n",
    "        word_vector=pca.fit_transform(cooccur_matrix)\n",
    "        return word_vector\n",
    "        \n",
    "    \n",
    "\n",
    "    def q23_similarity(self,word):\n",
    "        '''\n",
    "        Arguments\n",
    "            word (str): input keyword\n",
    "            word_vectors (np.ndarray): Nxdim word-vector matrix\n",
    "            vocab (dict): map keyword into id\n",
    "            inv_vocab (dict): map id back to keyword\n",
    "        Returns\n",
    "            top3: list of 3 tuple, each tuple consists of (word, similarity)\n",
    "        '''\n",
    "        self.word = word\n",
    "        word_vector = self.q22_word_vectors()\n",
    "        vocab , inv_vocab =self.q21_cooccur_matrix()[0:2]\n",
    "        #字詞間的相似度\n",
    "        dist_out = 1-pairwise_distances(word_vector, metric=\"cosine\")\n",
    "        #透過argsort找到array排序的前三的位置, 有負號是表示降幕,[1:4],是因為位置0是自己\n",
    "        pos = np.argsort(-dist_out[vocab[self.word]])[1:4]\n",
    "        top3 = list([(inv_vocab[pos[0]],dist_out[vocab[self.word],pos[0]]),\n",
    "                (inv_vocab[pos[1]],dist_out[vocab[self.word],pos[1]]),\n",
    "                (inv_vocab[pos[2]],dist_out[vocab[self.word],pos[2]])])\n",
    "        return top3\n",
    "    \n",
    "    def most_similar(self,word):\n",
    "        self.word = word\n",
    "        top3 = self.q23_similarity(self.word)\n",
    "        return top3\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group 0.99987421894631\n",
      "director 0.9998301731167207\n",
      "center 0.9998272397288703\n"
     ]
    }
   ],
   "source": [
    "wv = WordVector('raw_sentences.txt')\n",
    "for word, sim in wv.most_similar('office'):\n",
    "    print(word, sim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
