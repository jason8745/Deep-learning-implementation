{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-02b855d8d526>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\a0970\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取1000筆資料訓練就好\n",
    "test1,test2=mnist.test.next_batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(test1.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "first_train_img = np.reshape(test1[0], (28, 28))\n",
    "plt.matshow(first_train_img, cmap = plt.get_cmap('gray'))\n",
    "plt.savefig('mnist_1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義CNN的參數\n",
    "learning_rate=0.001\n",
    "training_iters=100000\n",
    "batch_size=128\n",
    "display_step=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每個形狀為28*28的像素\n",
    "n_input=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#答案為0~9\n",
    "n_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#為了減少過度配飾,我們使用dropout來丟棄單元\n",
    "dropout=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#為輸入圖形定義placeholder \n",
    "x=tf.placeholder(tf.float32,[None,n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用reshape將4D輸入資料改成張量(這裡仍需理解)\n",
    "#2,3維為寬度和高度,第四維為顏色的總數\n",
    "_X=tf.reshape(x,shape=[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= tf.placeholder(tf.float32,[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷基層的每一個神經元連接到維度大小為5*5的輸入張量,因此隱藏層的大小為28+1-5=24\n",
    "#wcl為共享權重,bcl為共享偏差\n",
    "#32代表我們設定了32個特徵圖譜\n",
    "wc1= tf.Variable(tf.random_normal([5,5,1,32]))\n",
    "bc1= tf.Variable(tf.random_normal([32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建構卷基層\n",
    "#激活層使用relu\n",
    "#strides設定為1\n",
    "#padding='SAME',會使用zero-padding策略,讓圖不受到kernal map大小影響\n",
    "#padding=\"VALID\",不使用zero-padding,圖的大小會因為kernal map 受影響 \n",
    "def conv2d(img,w,b):\n",
    "    return tf.nn.relu(tf.nn.bias_add\\\n",
    "                     (tf.nn.conv2d(img,w,\\\n",
    "                                  strides=[1,1,1,1],\n",
    "                                  padding='SAME'),b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一層\n",
    "conv1= conv2d(_X,wc1,bc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#池化層建構\n",
    "#池化策略選擇max_pooling\n",
    "#池化的目標是將資料再度壓縮,會將資料壓縮成k*k\n",
    "#\n",
    "def max_pool(img,k):\n",
    "    return tf.nn.max_pool(img,\n",
    "                         ksize=[1,k,k,1],\n",
    "                         strides=[1,k,k,1],\n",
    "                         padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#池化層建構\n",
    "conv1=max_pool(conv1,k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最後一層進行dropout處理\n",
    "keep_prob=tf.placeholder(tf.float32)\n",
    "conv1= tf.nn.dropout(conv1,keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此conv1就是我們第一層的輸出了,cnn就是一層一層的把CNN架起來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二卷積層\n",
    "#第二隱藏層將具有5*5窗口的64個特徵,輸入層的數量將來自第一卷積層.我們對32個conv1層,應用64組5*5的過濾器\n",
    "wc2=tf.Variable(tf.random_normal([5,5,32,64]))\n",
    "bc2=tf.Variable(tf.random_normal([64]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重複在conv1的操作\n",
    "conv2= conv2d(conv1,wc2,bc2)\n",
    "conv2=max_pool(conv2,k=2)\n",
    "conv2=tf.nn.dropout(conv2, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立全連接層\n",
    "#1024個神經元\n",
    "wd1=tf.Variable(tf.random_normal([7*7*64,1024]))\n",
    "bd1=tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "#將張量從第二卷積層(7*7*64)重塑成一個向量\n",
    "#flattern\n",
    "dense1= tf.reshape(conv2,[-1,wd1.get_shape().as_list()[0]])\n",
    "#dense1*wd1+bd1\n",
    "dense1= tf.nn.relu(tf.add(tf.matmul(dense1,wd1),bd1))\n",
    "\n",
    "dense1=tf.nn.dropout(dense1,keep_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output層\n",
    "wout= tf.Variable(tf.random_normal([1024,n_classes]))\n",
    "bout= tf.Variable(tf.random_normal([n_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= tf.add(tf.matmul(dense1,wout),bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#預測模型\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最佳化\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用於評估階段\n",
    "correct_pred=tf.equal(tf.argmax(pred,1),(tf.argmax(y,1)))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#啟動session\n",
    "init= tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1280  Minibatch_loss=24987.375000, Training Accuracy=0.17188\n",
      "iter 2560  Minibatch_loss=14644.159180, Training Accuracy=0.26562\n",
      "iter 3840  Minibatch_loss=9725.971680, Training Accuracy=0.51562\n",
      "iter 5120  Minibatch_loss=6126.162109, Training Accuracy=0.63281\n",
      "iter 6400  Minibatch_loss=5366.147461, Training Accuracy=0.63281\n",
      "iter 7680  Minibatch_loss=4399.464844, Training Accuracy=0.75000\n",
      "iter 8960  Minibatch_loss=3434.971436, Training Accuracy=0.78906\n",
      "iter 10240  Minibatch_loss=3860.717773, Training Accuracy=0.72656\n",
      "iter 11520  Minibatch_loss=4963.845215, Training Accuracy=0.77344\n",
      "iter 12800  Minibatch_loss=3639.841553, Training Accuracy=0.82031\n",
      "iter 14080  Minibatch_loss=2232.244629, Training Accuracy=0.78125\n",
      "iter 15360  Minibatch_loss=2262.990479, Training Accuracy=0.81250\n",
      "iter 16640  Minibatch_loss=2589.622559, Training Accuracy=0.82812\n",
      "iter 17920  Minibatch_loss=2392.213379, Training Accuracy=0.82812\n",
      "iter 19200  Minibatch_loss=2917.047119, Training Accuracy=0.79688\n",
      "iter 20480  Minibatch_loss=2321.482910, Training Accuracy=0.85938\n",
      "iter 21760  Minibatch_loss=2374.010742, Training Accuracy=0.82812\n",
      "iter 23040  Minibatch_loss=2769.619873, Training Accuracy=0.79688\n",
      "iter 24320  Minibatch_loss=1934.682617, Training Accuracy=0.81250\n",
      "iter 25600  Minibatch_loss=1091.464233, Training Accuracy=0.91406\n",
      "iter 26880  Minibatch_loss=1535.833252, Training Accuracy=0.87500\n",
      "iter 28160  Minibatch_loss=1325.554199, Training Accuracy=0.86719\n",
      "iter 29440  Minibatch_loss=1311.105469, Training Accuracy=0.89062\n",
      "iter 30720  Minibatch_loss=1510.106812, Training Accuracy=0.85938\n",
      "iter 32000  Minibatch_loss=1854.035278, Training Accuracy=0.84375\n",
      "iter 33280  Minibatch_loss=1274.661865, Training Accuracy=0.88281\n",
      "iter 34560  Minibatch_loss=387.792053, Training Accuracy=0.95312\n",
      "iter 35840  Minibatch_loss=2157.456543, Training Accuracy=0.83594\n",
      "iter 37120  Minibatch_loss=1749.944824, Training Accuracy=0.82812\n",
      "iter 38400  Minibatch_loss=568.395264, Training Accuracy=0.90625\n",
      "iter 39680  Minibatch_loss=1956.679932, Training Accuracy=0.82812\n",
      "iter 40960  Minibatch_loss=865.859680, Training Accuracy=0.89844\n",
      "iter 42240  Minibatch_loss=804.169922, Training Accuracy=0.91406\n",
      "iter 43520  Minibatch_loss=1055.146729, Training Accuracy=0.89844\n",
      "iter 44800  Minibatch_loss=1325.021851, Training Accuracy=0.88281\n",
      "iter 46080  Minibatch_loss=1288.375610, Training Accuracy=0.87500\n",
      "iter 47360  Minibatch_loss=885.593872, Training Accuracy=0.92969\n",
      "iter 48640  Minibatch_loss=956.961792, Training Accuracy=0.87500\n",
      "iter 49920  Minibatch_loss=1294.403076, Training Accuracy=0.87500\n",
      "iter 51200  Minibatch_loss=600.936646, Training Accuracy=0.92188\n",
      "iter 52480  Minibatch_loss=1194.552246, Training Accuracy=0.88281\n",
      "iter 53760  Minibatch_loss=776.655151, Training Accuracy=0.91406\n",
      "iter 55040  Minibatch_loss=816.115479, Training Accuracy=0.89844\n",
      "iter 56320  Minibatch_loss=377.901062, Training Accuracy=0.96094\n",
      "iter 57600  Minibatch_loss=1504.618530, Training Accuracy=0.89062\n",
      "iter 58880  Minibatch_loss=129.672852, Training Accuracy=0.93750\n",
      "iter 60160  Minibatch_loss=959.794067, Training Accuracy=0.92188\n",
      "iter 61440  Minibatch_loss=1000.639832, Training Accuracy=0.90625\n",
      "iter 62720  Minibatch_loss=478.025574, Training Accuracy=0.92969\n",
      "iter 64000  Minibatch_loss=1247.685791, Training Accuracy=0.89844\n",
      "iter 65280  Minibatch_loss=532.843445, Training Accuracy=0.93750\n",
      "iter 66560  Minibatch_loss=843.281982, Training Accuracy=0.93750\n",
      "iter 67840  Minibatch_loss=570.000488, Training Accuracy=0.89844\n",
      "iter 69120  Minibatch_loss=905.544067, Training Accuracy=0.87500\n",
      "iter 70400  Minibatch_loss=325.722076, Training Accuracy=0.93750\n",
      "iter 71680  Minibatch_loss=476.877380, Training Accuracy=0.92969\n",
      "iter 72960  Minibatch_loss=327.112610, Training Accuracy=0.92188\n",
      "iter 74240  Minibatch_loss=329.057251, Training Accuracy=0.92969\n",
      "iter 75520  Minibatch_loss=728.173340, Training Accuracy=0.89062\n",
      "iter 76800  Minibatch_loss=1136.310303, Training Accuracy=0.87500\n",
      "iter 78080  Minibatch_loss=864.030457, Training Accuracy=0.89844\n",
      "iter 79360  Minibatch_loss=753.342651, Training Accuracy=0.89844\n",
      "iter 80640  Minibatch_loss=399.817474, Training Accuracy=0.95312\n",
      "iter 81920  Minibatch_loss=322.357727, Training Accuracy=0.92969\n",
      "iter 83200  Minibatch_loss=784.562744, Training Accuracy=0.86719\n",
      "iter 84480  Minibatch_loss=513.647217, Training Accuracy=0.92969\n",
      "iter 85760  Minibatch_loss=328.937378, Training Accuracy=0.92969\n",
      "iter 87040  Minibatch_loss=230.703674, Training Accuracy=0.95312\n",
      "iter 88320  Minibatch_loss=503.108887, Training Accuracy=0.92969\n",
      "iter 89600  Minibatch_loss=611.856445, Training Accuracy=0.90625\n",
      "iter 90880  Minibatch_loss=629.410522, Training Accuracy=0.91406\n",
      "iter 92160  Minibatch_loss=947.748352, Training Accuracy=0.88281\n",
      "iter 93440  Minibatch_loss=856.689087, Training Accuracy=0.89062\n",
      "iter 94720  Minibatch_loss=544.273926, Training Accuracy=0.92188\n",
      "iter 96000  Minibatch_loss=316.113434, Training Accuracy=0.96094\n",
      "iter 97280  Minibatch_loss=397.224640, Training Accuracy=0.92969\n",
      "iter 98560  Minibatch_loss=398.138855, Training Accuracy=0.93750\n",
      "iter 99840  Minibatch_loss=342.840607, Training Accuracy=0.92969\n",
      "optimization Finished!\n",
      "Testing Accuracy: 0.9296875\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #initialize\n",
    "    sess.run(init)\n",
    "    step=1\n",
    "    #keep training until reach max iteration\n",
    "    while step*batch_size <training_iters:\n",
    "        batch_xs,batch_ys= mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer,feed_dict={x:batch_xs,\n",
    "                                     y:batch_ys,\n",
    "                                     keep_prob:dropout})\n",
    "        if step% display_step==0:\n",
    "            #calculate batch accuracy\n",
    "            acc= sess.run(accuracy,feed_dict={x:batch_xs,\n",
    "                                             y:batch_ys,\n",
    "                                             keep_prob:1.0})\n",
    "            loss=sess.run(cost,feed_dict={x:batch_xs,\n",
    "                                         y:batch_ys,\n",
    "                                         keep_prob:1.0})\n",
    "            print(\"iter \"+str(step*batch_size)+\"  Minibatch_loss=\"+\"{:.6f}\".format(loss)+\", Training Accuracy=\"+\"{:.5f}\".format(acc))\n",
    "        step+=1\n",
    "    print(\"optimization Finished!\")\n",
    "    print('Testing Accuracy:',sess.run(accuracy,feed_dict={x:mnist.test.images[:256],\n",
    "                                                          y:mnist.test.labels[:256],\n",
    "                                                          keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
